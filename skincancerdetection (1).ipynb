{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc75814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:03:41.915407Z",
     "iopub.status.busy": "2025-03-27T19:03:41.915119Z",
     "iopub.status.idle": "2025-03-27T19:03:59.324849Z",
     "shell.execute_reply": "2025-03-27T19:03:59.323677Z"
    },
    "id": "Z0s5N8Mcao6_",
    "outputId": "9d61eb01-a6b5-4196-c7d9-7f32528698e3",
    "papermill": {
     "duration": 17.414537,
     "end_time": "2025-03-27T19:03:59.326310",
     "exception": false,
     "start_time": "2025-03-27T19:03:41.911773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 248 ms, sys: 72.9 ms, total: 321 ms\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from IPython.display import clear_output\n",
    "!pip install ultralytics ultralytics-hub\n",
    "!pip install roboflow\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install opencv-python\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113fec4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:03:59.332286Z",
     "iopub.status.busy": "2025-03-27T19:03:59.332030Z",
     "iopub.status.idle": "2025-03-27T19:06:12.854510Z",
     "shell.execute_reply": "2025-03-27T19:06:12.853648Z"
    },
    "id": "FwRzcC0WkSnB",
    "outputId": "ad8118eb-4382-4854-f1b9-efc935f1fdf2",
    "papermill": {
     "duration": 133.52737,
     "end_time": "2025-03-27T19:06:12.856471",
     "exception": false,
     "start_time": "2025-03-27T19:03:59.329101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"cBU8lFOC0t6ANNTPCksS\")\n",
    "project = rf.workspace(\"skincancerproject-85mbz\").project(\"skin-cancer-rf9os\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"folder\")\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4654a103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:06:12.879975Z",
     "iopub.status.busy": "2025-03-27T19:06:12.879714Z",
     "iopub.status.idle": "2025-03-27T19:06:24.280873Z",
     "shell.execute_reply": "2025-03-27T19:06:24.280126Z"
    },
    "id": "iU3zzv41dgdl",
    "outputId": "21fece3c-eb41-4fad-b8e5-95a4a7cb1d2d",
    "papermill": {
     "duration": 11.405708,
     "end_time": "2025-03-27T19:06:24.282426",
     "exception": false,
     "start_time": "2025-03-27T19:06:12.876718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-cls.pt to 'yolov8m-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32.7M/32.7M [00:01<00:00, 30.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8m-cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "221caaef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:06:24.290707Z",
     "iopub.status.busy": "2025-03-27T19:06:24.290374Z",
     "iopub.status.idle": "2025-03-27T19:06:24.295888Z",
     "shell.execute_reply": "2025-03-27T19:06:24.295128Z"
    },
    "papermill": {
     "duration": 0.010721,
     "end_time": "2025-03-27T19:06:24.297051",
     "exception": false,
     "start_time": "2025-03-27T19:06:24.286330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "data_yaml = {\n",
    "    \"train\": \"/kaggle/working/Skin-Cancer-2/train\",\n",
    "    \"val\": \"/kaggle/working/Skin-Cancer-2/valid\",\n",
    "    \"nc\": 2,  # Number of classes, update as per your dataset\n",
    "    \"names\": [\"benign\", \"malignant\"]  # Replace with actual class names\n",
    "}\n",
    "\n",
    "with open(\"/kaggle/working/data.yaml\", \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(\"data.yaml file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8946c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:06:24.303430Z",
     "iopub.status.busy": "2025-03-27T19:06:24.303227Z",
     "iopub.status.idle": "2025-03-27T19:06:24.309145Z",
     "shell.execute_reply": "2025-03-27T19:06:24.308205Z"
    },
    "papermill": {
     "duration": 0.011128,
     "end_time": "2025-03-27T19:06:24.311067",
     "exception": false,
     "start_time": "2025-03-27T19:06:24.299939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Path Exists: True\n",
      "Validation Path Exists: True\n",
      "Train Classes: ['benign', 'malignant']\n",
      "Validation Classes: ['benign', 'malignant']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"/kaggle/working/Skin-Cancer-2/train\"\n",
    "val_path = \"/kaggle/working/Skin-Cancer-2/valid\"\n",
    "\n",
    "print(\"Train Path Exists:\", os.path.exists(train_path))\n",
    "print(\"Validation Path Exists:\", os.path.exists(val_path))\n",
    "\n",
    "# Check contents of the directories\n",
    "print(\"Train Classes:\", os.listdir(train_path) if os.path.exists(train_path) else \"Path not found\")\n",
    "print(\"Validation Classes:\", os.listdir(val_path) if os.path.exists(val_path) else \"Path not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d7bf3f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T19:06:24.322533Z",
     "iopub.status.busy": "2025-03-27T19:06:24.322272Z",
     "iopub.status.idle": "2025-03-28T02:26:49.186786Z",
     "shell.execute_reply": "2025-03-28T02:26:49.185969Z"
    },
    "id": "fu8lJdMkdne0",
    "outputId": "ac84e16a-318d-4f9f-c45f-df9d511a0a2f",
    "papermill": {
     "duration": 26424.870606,
     "end_time": "2025-03-28T02:26:49.188949",
     "exception": false,
     "start_time": "2025-03-27T19:06:24.318343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.97 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=/kaggle/working/Skin-Cancer-2, epochs=30, time=None, patience=10, batch=32, imgsz=640, save=True, save_period=-1, cache=ram, device=[0, 1], workers=8, project=skin_cancer_classification, name=yolov8n_cls, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=skin_cancer_classification/yolov8n_cls\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/Skin-Cancer-2/train... found 79370 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/Skin-Cancer-2/test... found 529 images in 2 classes ‚úÖ \n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
      "YOLOv8m-cls summary: 80 layers, 15,774,898 parameters, 15,774,898 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 39253 /root/.config/Ultralytics/DDP/_temp_e045s6jm133189633573216.py\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "    data='/kaggle/working/Skin-Cancer-2',\n",
    "    epochs=30,\n",
    "    imgsz=640,  # Consider reducing to 512 if acceptable for your task\n",
    "    batch=32,  # Increased batch size for dual T4 GPUs\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    dropout=0.2,\n",
    "    project='skin_cancer_classification',\n",
    "    name='yolov8n_cls',\n",
    "    device=[0,1],  # Explicitly use both GPUs\n",
    "    weight_decay=0.0005,\n",
    "    amp=True,  # Crucial for T4 GPUs (they have Tensor Cores)\n",
    "    workers=8,  # Kaggle works best with 4-8 workers\n",
    "    cache='ram',  # Cache dataset in RAM if you have enough\n",
    "    patience=10,  # Early stopping to avoid unnecessary epochs\n",
    "    pretrained=True,  # Ensure you're using pretrained weights\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06469f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T02:26:49.200623Z",
     "iopub.status.busy": "2025-03-28T02:26:49.199826Z",
     "iopub.status.idle": "2025-03-28T02:26:49.246632Z",
     "shell.execute_reply": "2025-03-28T02:26:49.245902Z"
    },
    "id": "uVKaZHFTu84Y",
    "papermill": {
     "duration": 0.05331,
     "end_time": "2025-03-28T02:26:49.247900",
     "exception": false,
     "start_time": "2025-03-28T02:26:49.194590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e543f16e-f647-474d-9ae0-a67132ea59f8\", \"best.pt\", 31682009)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"/kaggle/working/skin_cancer_classification/yolov8n_cls/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e956cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T02:26:49.256658Z",
     "iopub.status.busy": "2025-03-28T02:26:49.256424Z",
     "iopub.status.idle": "2025-03-28T02:27:01.205027Z",
     "shell.execute_reply": "2025-03-28T02:27:01.204155Z"
    },
    "id": "--41hPYVj--q",
    "papermill": {
     "duration": 11.954339,
     "end_time": "2025-03-28T02:27:01.206314",
     "exception": false,
     "start_time": "2025-03-28T02:26:49.251975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.97 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "YOLOv8m-cls summary (fused): 42 layers, 15,765,218 parameters, 0 gradients, 41.6 GFLOPs\n",
      "WARNING ‚ö†Ô∏è Dataset 'split=val' not found, using 'split=test' instead.\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /kaggle/working/Skin-Cancer-2/train... found 79370 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /kaggle/working/Skin-Cancer-2/test... found 529 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /kaggle/working/Skin-Cancer-2/test... found 529 images in 2 classes ‚úÖ \n",
      "WARNING ‚ö†Ô∏è Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/Skin-Cancer-2/test... 529 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 529/529 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:08<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.941          1\n",
      "Speed: 0.4ms preprocess, 12.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mskin_cancer_classification/yolov8n_cls2\u001b[0m\n",
      "0.9413988590240479\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()\n",
    "print(metrics.top1)  # top-1 accuracy\n",
    "print(metrics.top5)  # top-5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf76748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T02:27:01.219037Z",
     "iopub.status.busy": "2025-03-28T02:27:01.218473Z",
     "iopub.status.idle": "2025-03-28T02:27:01.551348Z",
     "shell.execute_reply": "2025-03-28T02:27:01.550233Z"
    },
    "id": "boLkZ9L3dpYr",
    "papermill": {
     "duration": 0.340291,
     "end_time": "2025-03-28T02:27:01.552608",
     "exception": true,
     "start_time": "2025-03-28T02:27:01.212317",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClassifyMetrics' object has no attribute 'box'. See valid attributes below.\n\n    Class for computing classification metrics including top-1 and top-5 accuracy.\n\n    Attributes:\n        top1 (float): The top-1 accuracy.\n        top5 (float): The top-5 accuracy.\n        speed (dict): A dictionary containing the time taken for each step in the pipeline.\n        task (str): The task type, set to 'classify'.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-362b7d07351a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print mAP (mean Average Precision)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;34m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ClassifyMetrics' object has no attribute 'box'. See valid attributes below.\n\n    Class for computing classification metrics including top-1 and top-5 accuracy.\n\n    Attributes:\n        top1 (float): The top-1 accuracy.\n        top5 (float): The top-5 accuracy.\n        speed (dict): A dictionary containing the time taken for each step in the pipeline.\n        task (str): The task type, set to 'classify'.\n    "
     ]
    }
   ],
   "source": [
    "print(metrics.box.map)  # Print mAP (mean Average Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20920c9c",
   "metadata": {
    "execution": {
     "execution_failed": "2025-03-27T18:33:24.095Z"
    },
    "id": "SggLFpwSk4u6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO(\"runs/detect/yolo11n_finetuned2/weights/best.pt\")  # Update with your trained model path\n",
    "\n",
    "# Path to the folder containing test images\n",
    "image_folder = \"/content/Implant-Doctor-1/test/images\"  # Change this to your test image folder\n",
    "output_folder = \"./output\"  # Change this to where you want to save results\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of images (limit to 6 images)\n",
    "image_paths = glob.glob(os.path.join(image_folder, \"*.jpg\"))[:10]\n",
    "\n",
    "# Run inference on images\n",
    "for img_path in image_paths:\n",
    "    results = model(img_path)  # Run YOLO model on the image\n",
    "\n",
    "    # Save the result image with bounding boxes\n",
    "    for result in results:\n",
    "        img = result.plot()  # Get the image with detections\n",
    "        output_path = os.path.join(output_folder, os.path.basename(img_path))\n",
    "        cv2.imwrite(output_path, img)\n",
    "\n",
    "print(\"Inference completed. Results saved in:\", output_folder)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26605.489091,
   "end_time": "2025-03-28T02:27:04.829076",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-27T19:03:39.339985",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
